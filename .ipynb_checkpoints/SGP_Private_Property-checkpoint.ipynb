{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore Private Property Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Loading Packages & Reading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir(\"C:\\Python\\data\\project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartment = pd.read_csv(\"Apartments.csv\", index_col=False)\n",
    "condos = pd.read_csv(\"Condos.csv\", index_col=False)\n",
    "ec = pd.read_csv(\"Executive Condos.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Understanding the Size of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(apartment), len(condos), len(ec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Combining All Datasets into a Single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([apartment, condos, ec])\n",
    "print(\"The total number of observations in the combined dataset is\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Preliminary Data Exploration Using ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Profile Report, there are various important items to take note of as follow:\n",
    "1. There were several projects that had unknown completion dates, and their age was wrongly calculated as a result. To ensure the Age column has correct values, we manually found the completion dates of these 88 projects online and imputed these values into the dataset.\n",
    "\n",
    "2. There are transactions that have more than 1 unit. In order to allow our model to be more robust and to focus on predicting property prices for transactions involving only 1 unit, we will remove transactions that have more than 1 unit.\n",
    "\n",
    "3. Various transactions have missing values. In this case, we will remove transactions with no facilities information, impute missing values for Floor No, Floor No (Final) and Unit No as zero.\n",
    "\n",
    "4. There are several variables that would not be useful in training our models. Therefore, these variables will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Impute Completion Dates for 88 Projects And Recalculate Property Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Impute Completion Dates for 88 Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in list of completion dates manually found\n",
    "comp_date = pd.read_csv(\"Projects with Completion Date.csv\", index_col = None, dtype = {'Completion Date': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check projects with currently unknown completion dates\n",
    "df[df[\"Completion Date\"] == \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set projects with unknown completion dates to a value of None\n",
    "df.loc[df['Completion Date'] == \"Unknown\", 'Completion Date'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the dataframes using Project Name\n",
    "df = df.set_index(\"Project Name\")\n",
    "comp_date = comp_date.set_index(\"Project Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the None values have been set correctly\n",
    "df[df[\"Completion Date\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values\n",
    "df[\"Completion Date\"] = df['Completion Date'].fillna(comp_date['Completion Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Completion Date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Recalculate Property Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with unknown completion date\n",
    "df = df[df[\"Completion Date\"].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Completion Date\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the case of uncompleted projects at time of sale, the age of the property should be set as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sale Date\"] = pd.to_datetime(df[\"Sale Date\"], format = \"%d-%b-%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"] = df.apply(lambda x: x[\"Sale Date\"].year - int(x[\"Completion Date\"]) if (x[\"Completion Date\"] != \"Uncompleted\") else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Age'] < 0, 'Age'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Removing Transactions Involving More Than 1 Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[df[\"No. of Units\"] == 1] # 38 records\n",
    "print(\"The total number of observations after removing transactions involving more than 1 unit is now\", len(df_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Removing Transactions with No Facilities Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new[\"Carpark\"].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns[df_new.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Impute Missing Values for Floor No., Floor No. (Final) and Unit No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Floor No\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 0 for units without Floor No\n",
    "df_new['Floor No'][df_new['Floor No'].isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Floor No\"] = df_new[\"Floor No\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 0 for units without Unit No\n",
    "df_new['Unit No'][df_new['Unit No'].isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Unit No\"] = df_new[\"Unit No\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Floor No (Final)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Floor No (Final)\"][df_new[\"Floor No (Final)\"].isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Floor No (Final)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Remove Unwanted Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop([\"SN\", \n",
    "                      \"Project Name\", \n",
    "                      \"Address\", \n",
    "                      \"No. of Units\", \n",
    "                      \"Type of Area\", \n",
    "                      \"Nett Price($)\", \n",
    "                      \"Unit Price ($ psm)\", \n",
    "                      #\"Unit Price ($ psf)\",\n",
    "                      \"Sale Date\",\n",
    "                      \"Address 1\",\n",
    "                      \"Address for Geocode\",\n",
    "                      \"Lease Start Date\",\n",
    "                      \"Latitude\",\n",
    "                      \"Longitude\",\n",
    "                      \"Completion Date\",\n",
    "                      \"Postal Sector\",\n",
    "                      \"Postal Code\",\n",
    "                      \"Planning Region\",\n",
    "                      \"Tenure\",\n",
    "                      \"Tenure (New)\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns[df_new.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Exporting Preliminarily Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"Cleaned Dataset_v3.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Exported Dataset\n",
    "df = pd.read_csv(\"Cleaned Dataset_v3.csv\", index_col=None, dtype = {'Unit No': str, 'Floor No': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Additional Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Loading Additional Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import  metrics, linear_model, ensemble, model_selection,feature_selection\n",
    "from yellowbrick.regressor import PredictionError\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Reading New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Cleaned Dataset_v3.csv\", index_col=None, dtype = {'Unit No': str, 'Floor No': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Using ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading our dataset, we will perform additional data exploration using the pandas_profiling package, which allows us to gain insights on the following:\n",
    "1. Dataset Information\n",
    "    a. Number of Variables\n",
    "    b. Number of Observations\n",
    "    c. Total Percentage of Missing Observations\n",
    "2. Variable Types\n",
    "3. Warnings on the following:\n",
    "    a. Variables with large numbers of zeros\n",
    "    b. Variables that are highly correlated\n",
    "    c. Variables with unsupported data type\n",
    "    d. Variables with high cardinality\n",
    "    e. Presence and number of duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp\n",
    "pp.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Discussion on ProfileReport\n",
    "Based on the Profile Report above, we can see that there are several pairs of variables with high correlation. These variables are:\n",
    "1. Condominiums and Private Flats Households (% of Total Households) AND Resident in Condominiums and Other Apartments (% of total residents)\n",
    "Correlation Coefficient = 0.94806\n",
    "\n",
    "2. Time(Month) AND Time(Quarter)\n",
    "Correlation Coefficient = 0.99722\n",
    "\n",
    "3. Uni Qualification (% of total) AND Monthly Household Income $8000 and above (% of Total Households)\n",
    "Correlation Coefficient = 0.90933\n",
    "\n",
    "In order to identify other possible highly correlated independent variables, we will plot an IV-IV correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Independent Variable - Independent Variable Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Discussion on IV-IV Correlation Matrix\n",
    "\n",
    "Based on the IV-IV Correlation Matrix above, we can see that other than the IV pairs highlighted from the ProfileReport that are highly correlated, the following variable pair is also highly correlated:\n",
    "\n",
    "#### 1. Condominiums and Private Flats Households (% of Total Households) AND Uni Qualification (% of total)\n",
    "0.914189\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 Summary of Data Exploration\n",
    "\n",
    "Based on the above, we will be performing further data pre-processing as indicated below:\n",
    "\n",
    "1. Changing Area (sqm) to Area (sqf)\n",
    "2. Dropping Unnecessary columns\n",
    "3. Dropping One Variable in Each Pair of Highly Correlated Variables\n",
    "4. Dropping Variables Due to Business Domain Reasons\n",
    "5. Log Distance\n",
    "6. Create Expensive Area Indicator\n",
    "7. Converting Categorical Data Types - Creating Dummy Variables\n",
    "8. Create Lucky and Unlucky Unit No and Floor No\n",
    "9. Re-arranging Target Variable, 'Unit Price (psf)', To the Last Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Additional Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Changing Area (sqm) to Area (sqf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Area (sqf)'] = df['Area (sqm)']*10.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Dropping Unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#three years data not enought to look at time series\n",
    "\n",
    "df = df.drop(['Transacted Price ($)','LN (Price)','Area (sqm)','Sale YM','Time (Quarter)','Time (Month)'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Dropping One Variable in Each Pair of Highly Correlated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df.drop(['Resident in Condominiums and Other Apartments (% of total residents)','Monthly Household Income $8000 and above (% of Total Households)','Condominiums and Private Flats Households (% of Total Households)'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Dropping Variables Due to Business Domain Reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Postal District','Chill Out'],axis = 1)\n",
    "#Dropping postal district and keeping planning area\n",
    "#Dropping chill out between chill out and food/dining due to contingency table showing that both follow similar pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Log Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on business intuition, it can be assumed that short and long distances are more important in predicting property prices. Therefore, we want to perform data transformation on these features to reflect this intuition. Additionally, when we visualize an example of one of the distance features, bus stop km, onto a histogram, we can see that the datapoints are typically skewed. Correspondingly, the data distribution does not closely follow the diagonal line in the probability plot that represents normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#histogram and normal probability plot\n",
    "sns.distplot(df['bus stop km'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['bus stop km'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon log transformation, we can see that the data distribution now follows a normal distribution more closely based on the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(np.log(df['bus stop km']), fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(np.log(df['bus stop km']), plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we want to perform a log transformation on all distance variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,14:35] = np.log(df.iloc[:,14:35]+0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Create Expensive Area Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x = df[\"Planning Area\"],y = df[\"CBD km\"])\n",
    "plt.title(\"Boxplot of CBD km Against Planning Area\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x = df[\"Planning Area\"],y = df[\"Unit Price ($ psf)\"])\n",
    "plt.title(\"Boxplot of CBD km Against Planning Area\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the two plots above, we can see that for Planning Areas such as Newton, Orchard, River Valley, Downtown Core and Museum, the price range of properties in these area tend to be of a relatively higher price than other properties even though they might not be the nearest to the CBD as compared to other planning areas. For example, properties in Rochor seems to be nearer to CBD, but the price range of these properties are not as high as properties in Musuem. In this case, we want to construct an additional feature \"Expensive_Area_Indicator\" to be fed into our models to make our models more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expensive_area_indicator(df):\n",
    "    if df['Planning Area'] =='Newton':  \n",
    "        indicator = 1\n",
    "    elif df['Planning Area'] == 'Orchard':\n",
    "        indicator = 1\n",
    "    elif df['Planning Area'] == 'River Valley':\n",
    "        indicator = 1\n",
    "    elif df['Planning Area'] == 'Downtown Core':\n",
    "        indicator = 1\n",
    "    elif df['Planning Area'] == 'Museum':\n",
    "        indicator = 1\n",
    "    else:\n",
    "        indicator = 0\n",
    "    return indicator\n",
    "\n",
    "\n",
    "df['Expensive_Area_Indicator'] = df.apply(expensive_area_indicator, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. Converting Categorical Data Types - Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit the categorical data into our models, we have to first create dummy variables for our categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummy = pd.get_dummies(df,columns = ['Purchaser Address Indicator','Planning Area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8. Create Lucky and Unlucky Unit No and Floor No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Singapore, auspicious or inauspicious numbers are typically considered when one purchases new goods or services. This belief could therefore extend to the purchase of properties as well. Therefore, based on social-cultural factors in the local context, the following features were created as they are likely to be important in influencing buyersâ€™ decision in purchasing a property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isunluckyunit(df):\n",
    "    string = df['Unit No']\n",
    "    result = 0\n",
    "    if string.isdigit() == True:\n",
    "        number = int(string)\n",
    "        if number == 4:\n",
    "               result = 1\n",
    "        elif number == 44:\n",
    "                result = 1\n",
    "        elif number == 144:\n",
    "                result = 1\n",
    "        elif number == 244:\n",
    "                result = 1\n",
    "        elif number == 344:\n",
    "                result = 1    \n",
    "        else:\n",
    "            result = 0\n",
    "    return result\n",
    "\n",
    "def isunluckyfloor(df):\n",
    "    string = df['Floor No']\n",
    "    result = 0\n",
    "    if string.isdigit() == True:\n",
    "        number = int(string)\n",
    "        if number == 4:\n",
    "               result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "    return result\n",
    "\n",
    "def isluckyunit(df):\n",
    "    string = df['Unit No']\n",
    "    result = 0\n",
    "    if string.isdigit() == True:\n",
    "        number = int(string)\n",
    "        if number == 8:\n",
    "               result = 1\n",
    "        elif number == 88:\n",
    "                result = 1\n",
    "        elif number == 188:\n",
    "                result = 1\n",
    "        elif number == 6:\n",
    "                result = 1\n",
    "        elif number == 66:\n",
    "                result = 1\n",
    "   \n",
    "        else:\n",
    "            result = 0\n",
    "    return result\n",
    "\n",
    "def isluckyfloor(df):\n",
    "    string = df['Floor No']\n",
    "    result = 0\n",
    "    if string.isdigit() == True:\n",
    "        number = int(string)\n",
    "        if number == 8:\n",
    "               result = 1\n",
    "        elif number == 6:\n",
    "                result = 1   \n",
    "        else:\n",
    "            result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummy['Isunlucky Unit No'] = df_with_dummy.apply(isunluckyunit, axis=1)\n",
    "df_with_dummy['Islucky Unit No'] = df_with_dummy.apply(isluckyunit, axis=1)\n",
    "df_with_dummy['Isunlucky Floor No'] = df_with_dummy.apply(isunluckyfloor, axis=1)\n",
    "df_with_dummy['Islucky Floor No'] = df_with_dummy.apply(isluckyfloor, axis=1)\n",
    "\n",
    "df_with_dummy = df_with_dummy.drop(['Unit No','Floor No'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9. Re-arranging target variable, 'Unit Price (psf)', to the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of dataset before re-arrangement:', \"\\n\", df_with_dummy.shape, \"\\n\")\n",
    "cols = df_with_dummy.columns.tolist()\n",
    "print('Cols before re-arrangement:', \"\\n\", cols, \"\\n\")\n",
    "cols = cols[1:86] + cols[0:1]\n",
    "\n",
    "\n",
    "df_with_dummy = df_with_dummy[cols]\n",
    "print('shape of dataset after re-arrangement:', \"\\n\", df_with_dummy.shape, \"\\n\")\n",
    "print('Cols after re-arrangement:', \"\\n\", cols, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Spliting Dataset Into Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Split by Property Type and Sale Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condo = df_with_dummy[df_with_dummy['Property Type'] == \"Condominium\"]\n",
    "condo_NS = condo[condo['Type of Sale'] != \"Resale\"]\n",
    "condo_RS = condo[condo['Type of Sale'] == \"Resale\"]\n",
    "condo_NS = condo_NS.drop(['Property Type','Type of Sale'],axis = 1)\n",
    "condo_RS = condo_RS.drop(['Property Type','Type of Sale'],axis = 1)\n",
    "condo = condo.drop(['Property Type'],axis = 1)\n",
    "\n",
    "apart = df_with_dummy[df_with_dummy['Property Type'] == \"Apartment\"]\n",
    "apart_NS = apart[apart['Type of Sale'] != \"Resale\"]\n",
    "apart_RS = apart[(apart['Type of Sale'] == \"Resale\")]\n",
    "apart_NS = apart_NS.drop(['Property Type','Type of Sale'],axis = 1)\n",
    "apart_RS = apart_RS.drop(['Property Type','Type of Sale'],axis = 1)\n",
    "apart = apart.drop(['Property Type'],axis = 1)\n",
    "\n",
    "Econdo = df_with_dummy[df_with_dummy['Property Type'] == \"Executive Condominium\"]\n",
    "Econdo_NS = Econdo[Econdo['Type of Sale'] != \"Resale\"]\n",
    "Econdo_RS = Econdo[(Econdo['Type of Sale'] == \"Resale\")]\n",
    "Econdo_NS = Econdo_NS.drop(['Property Type','Type of Sale'],axis = 1)\n",
    "Econdo_RS = Econdo_RS.drop(['Property Type','Type of Sale'],axis = 1)\n",
    "Econdo = Econdo.drop(['Property Type'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Split X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_apart_NS = apart_NS.iloc[:,:-1]\n",
    "y_apart_NS = apart_NS.iloc[:,-1]\n",
    "\n",
    "x_apart_RS = apart_RS.iloc[:,:-1]\n",
    "y_apart_RS = apart_RS.iloc[:,-1]\n",
    "\n",
    "x_condo_NS = condo_NS.iloc[:,:-1]\n",
    "y_condo_NS = condo_NS.iloc[:,-1]\n",
    "\n",
    "x_condo_RS = condo_RS.iloc[:,:-1]\n",
    "y_condo_RS = condo_RS.iloc[:,-1]\n",
    "\n",
    "x_Econdo_NS = Econdo_NS.iloc[:,:-1]\n",
    "y_Econdo_NS = Econdo_NS.iloc[:,-1]\n",
    "\n",
    "x_Econdo_RS = Econdo_RS.iloc[:,:-1]\n",
    "y_Econdo_RS = Econdo_RS.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "train_apart_NS = np.random.choice([True, False], x_apart_NS.shape[0], replace=True, p=[0.6, 0.4])\n",
    "train_apart_RS = np.random.choice([True, False], x_apart_RS.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "train_condo_NS = np.random.choice([True, False], x_condo_NS.shape[0], replace=True, p=[0.6, 0.4])\n",
    "train_condo_RS = np.random.choice([True, False], x_condo_RS.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "train_Econdo_NS = np.random.choice([True, False], x_Econdo_NS.shape[0], replace=True, p=[0.6, 0.4])\n",
    "train_Econdo_RS = np.random.choice([True, False], x_Econdo_RS.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "\n",
    "\n",
    "x_apart_NS_train, y_apart_NS_train = x_apart_NS.iloc[train_apart_NS, :], y_apart_NS.iloc[train_apart_NS]\n",
    "x_apart_NS_test, y_apart_NS_test = x_apart_NS.iloc[~train_apart_NS, :], y_apart_NS.iloc[~train_apart_NS]\n",
    "\n",
    "x_apart_RS_train, y_apart_RS_train = x_apart_RS.iloc[train_apart_RS, :], y_apart_RS.iloc[train_apart_RS]\n",
    "x_apart_RS_test, y_apart_RS_test = x_apart_RS.iloc[~train_apart_RS, :], y_apart_RS.iloc[~train_apart_RS]\n",
    "\n",
    "x_condo_NS_train, y_condo_NS_train = x_condo_NS.iloc[train_condo_NS, :], y_condo_NS.iloc[train_condo_NS]\n",
    "x_condo_NS_test, y_condo_NS_test = x_condo_NS.iloc[~train_condo_NS, :], y_condo_NS.iloc[~train_condo_NS]\n",
    "\n",
    "x_condo_RS_train, y_condo_RS_train = x_condo_RS.iloc[train_condo_RS, :], y_condo_RS.iloc[train_condo_RS]\n",
    "x_condo_RS_test, y_condo_RS_test = x_condo_RS.iloc[~train_condo_RS, :], y_condo_RS.iloc[~train_condo_RS]\n",
    "\n",
    "x_Econdo_NS_train, y_Econdo_NS_train = x_Econdo_NS.iloc[train_Econdo_NS, :], y_Econdo_NS.iloc[train_Econdo_NS]\n",
    "x_Econdo_NS_test, y_Econdo_NS_test = x_Econdo_NS.iloc[~train_Econdo_NS, :], y_Econdo_NS.iloc[~train_Econdo_NS]\n",
    "\n",
    "x_Econdo_RS_train, y_Econdo_RS_train = x_Econdo_RS.iloc[train_Econdo_RS, :], y_Econdo_RS.iloc[train_Econdo_RS]\n",
    "x_Econdo_RS_test, y_Econdo_RS_test = x_Econdo_RS.iloc[~train_Econdo_RS, :], y_Econdo_RS.iloc[~train_Econdo_RS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Back up all x of train and test data as original before standardization for linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_apart_NS_train_original = x_apart_NS_train\n",
    "x_apart_NS_test_original = x_apart_NS_test\n",
    "\n",
    "x_apart_RS_train_original = x_apart_RS_train\n",
    "x_apart_RS_test_original = x_apart_RS_test\n",
    "\n",
    "x_condo_NS_train_original =x_condo_NS_train\n",
    "x_condo_NS_test_orinigal =x_condo_NS_test\n",
    "\n",
    "x_condo_RS_train_original =x_condo_RS_train\n",
    "x_condo_RS_test_original =x_condo_RS_test\n",
    "\n",
    "x_Econdo_NS_train_orinigal =x_Econdo_NS_train\n",
    "x_Econdo_NS_test_original =x_Econdo_NS_test\n",
    "\n",
    "x_Econdo_RS_train_original =x_Econdo_RS_train\n",
    "x_Econdo_RS_test_original =x_Econdo_RS_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0.Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_apart_NS_train = scaler.fit_transform(x_apart_NS_train)\n",
    "x_apart_NS_test = scaler.transform(x_apart_NS_test)\n",
    "\n",
    "x_apart_RS_train = scaler.fit_transform(x_apart_RS_train)\n",
    "x_apart_RS_test = scaler.transform(x_apart_RS_test)\n",
    "\n",
    "x_condo_NS_train = scaler.fit_transform(x_condo_NS_train)\n",
    "x_condo_NS_test = scaler.transform(x_condo_NS_test)\n",
    "\n",
    "x_condo_RS_train = scaler.fit_transform(x_condo_RS_train)\n",
    "x_condo_RS_test = scaler.transform(x_condo_RS_test)\n",
    "\n",
    "x_Econdo_NS_train = scaler.fit_transform(x_Econdo_NS_train)\n",
    "x_Econdo_NS_test = scaler.transform(x_Econdo_NS_test)\n",
    "\n",
    "x_Econdo_RS_train = scaler.fit_transform(x_Econdo_RS_train)\n",
    "x_Econdo_RS_test = scaler.transform(x_Econdo_RS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 Apartments New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns_all = Econdo_NS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "MSE = []\n",
    "r2 = []\n",
    "complexity = []\n",
    "cost = []\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(x_apart_NS_train, y_apart_NS_train)\n",
    "    apartment_y_pred = lasso.predict(x_apart_NS_test)\n",
    "    error = metrics.mean_squared_error(apartment_y_pred, y_apart_NS_test)\n",
    "    MSE.append(error)\n",
    "    r2.append(lasso.score(x_apart_NS_test, y_apart_NS_test))\n",
    "    c = (np.linalg.norm(lasso.coef_, ord = 1))\n",
    "    complexity.append(c)\n",
    "    cost.append(error + (a*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE)\n",
    "plt.plot(range(5), MSE)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)\n",
    "plt.plot(range(5), r2)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity)\n",
    "plt.plot(range(5), complexity)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check variable importance from lasso regression\n",
    "lasso.set_params(alpha = 1)\n",
    "lasso.fit(x_apart_NS_train, y_apart_NS_train)\n",
    "lasso.predict(x_apart_NS_test)\n",
    "lasso_coef = lasso.coef_\n",
    "print(x_columns_all[np.argsort(np.absolute(lasso_coef))])\n",
    "print(np.sort(np.absolute(lasso_coef)))\n",
    "np.count_nonzero(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out top 10 features\n",
    "x_apart_NS_train_reg = x_apart_NS_train[:, np.argsort(np.absolute(lasso_coef))[-10:]]\n",
    "x_apart_NS_test_reg = x_apart_NS_test[:, np.argsort(np.absolute(lasso_coef))[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with 10 features\n",
    "reg = linear_model.LinearRegression().fit(x_apart_NS_train_reg, y_apart_NS_train)\n",
    "apartment_y_pred = reg.predict(x_apart_NS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_NS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_NS_train_reg, y_apart_NS_train)))\n",
    "\n",
    "apartment_y_pred = reg.predict(x_apart_NS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_NS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_NS_test_reg, y_apart_NS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out all selected features\n",
    "x_apart_NS_train_reg = x_apart_NS_train[:, np.argsort(np.absolute(lasso_coef))[-41:]]\n",
    "x_apart_NS_test_reg = x_apart_NS_test[:, np.argsort(np.absolute(lasso_coef))[-41:]]\n",
    "x_columns = x_columns_all[np.argsort(np.absolute(lasso_coef))][-41:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with all selected features\n",
    "reg = linear_model.LinearRegression().fit(x_apart_NS_train_reg, y_apart_NS_train)\n",
    "apartment_y_pred = reg.predict(x_apart_NS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_NS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_NS_train_reg, y_apart_NS_train)))\n",
    "\n",
    "apartment_y_pred = reg.predict(x_apart_NS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_NS_test))\n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_NS_test_reg, y_apart_NS_test)))\n",
    "\n",
    "reg_coef = reg.coef_\n",
    "print(x_columns[np.argsort(np.absolute(reg_coef))])\n",
    "print(np.sort(np.absolute(reg_coef)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(reg)\n",
    "\n",
    "visualizer.fit(x_apart_NS_train_reg, y_apart_NS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_apart_NS_test_reg, y_apart_NS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Apartments Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "MSE = []\n",
    "r2 = []\n",
    "complexity = []\n",
    "cost = []\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(x_apart_RS_train, y_apart_RS_train)\n",
    "    apartment_y_pred = lasso.predict(x_apart_RS_test)\n",
    "    error = metrics.mean_squared_error(apartment_y_pred, y_apart_RS_test)\n",
    "    MSE.append(error)\n",
    "    r2.append(lasso.score(x_apart_RS_test, y_apart_RS_test))\n",
    "    c = (np.linalg.norm(lasso.coef_, ord = 1))\n",
    "    complexity.append(c)\n",
    "    cost.append(error + (a*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE)\n",
    "plt.plot(range(5), MSE)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)\n",
    "plt.plot(range(5), r2)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity)\n",
    "plt.plot(range(5), complexity)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable importance for lasso regression\n",
    "lasso.set_params(alpha = 0.1)\n",
    "lasso.fit(x_apart_RS_train, y_apart_RS_train)\n",
    "lasso.predict(x_apart_RS_test)\n",
    "lasso_coef = lasso.coef_\n",
    "print(x_columns_all[np.argsort(np.absolute(lasso_coef))])\n",
    "print(np.sort(np.absolute(lasso_coef)))\n",
    "np.count_nonzero(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_apart_RS_train_reg = x_apart_RS_train[:, np.argsort(np.absolute(lasso_coef))[-10:]]\n",
    "x_apart_RS_test_reg = x_apart_RS_test[:, np.argsort(np.absolute(lasso_coef))[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "reg = linear_model.LinearRegression().fit(x_apart_RS_train_reg, y_apart_RS_train)\n",
    "apartment_y_pred = reg.predict(x_apart_RS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_RS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_RS_test_reg, y_apart_RS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_apart_RS_train_reg = x_apart_RS_train[:, np.argsort(np.absolute(lasso_coef))[-69:]]\n",
    "x_apart_RS_test_reg = x_apart_RS_test[:, np.argsort(np.absolute(lasso_coef))[-69:]]\n",
    "x_columns = x_columns_all[np.argsort(np.absolute(lasso_coef))][-69:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "reg = linear_model.LinearRegression().fit(x_apart_RS_train_reg, y_apart_RS_train)\n",
    "apartment_y_pred = reg.predict(x_apart_RS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_RS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_RS_train_reg, y_apart_RS_train)))\n",
    "\n",
    "apartment_y_pred = reg.predict(x_apart_RS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(apartment_y_pred, y_apart_RS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_apart_RS_test_reg, y_apart_RS_test)))\n",
    "\n",
    "#reg_coef = reg.coef_\n",
    "#print(x_columns[np.argsort(np.absolute(reg_coef))])\n",
    "#print(np.sort(np.absolute(reg_coef)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(reg)\n",
    "\n",
    "visualizer.fit(x_apart_RS_train_reg, y_apart_RS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_apart_RS_test_reg, y_apart_RS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4 Condominiums New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "MSE = []\n",
    "r2 = []\n",
    "complexity = []\n",
    "cost = []\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(x_condo_NS_train, y_condo_NS_train)\n",
    "    condo_y_pred = lasso.predict(x_condo_NS_test)\n",
    "    error = metrics.mean_squared_error(condo_y_pred, y_condo_NS_test)\n",
    "    MSE.append(error)\n",
    "    r2.append(lasso.score(x_condo_NS_test, y_condo_NS_test))\n",
    "    c = (np.linalg.norm(lasso.coef_, ord = 1))\n",
    "    complexity.append(c)\n",
    "    cost.append(error + (a*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE)\n",
    "plt.plot(range(5), MSE)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)\n",
    "plt.plot(range(5), r2)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity)\n",
    "plt.plot(range(5), complexity)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check variable importance for lasso regression\n",
    "lasso.set_params(alpha = 1)\n",
    "lasso.fit(x_condo_NS_train, y_condo_NS_train)\n",
    "lasso.predict(x_condo_NS_test)\n",
    "lasso_coef = lasso.coef_\n",
    "print(x_columns_all[np.argsort(np.absolute(lasso_coef))])\n",
    "print(np.sort(np.absolute(lasso_coef)))\n",
    "np.count_nonzero(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out top 10 features\n",
    "x_condo_NS_train_reg = x_condo_NS_train[:, np.argsort(np.absolute(lasso_coef))[-10:]]\n",
    "x_condo_NS_test_reg = x_condo_NS_test[:, np.argsort(np.absolute(lasso_coef))[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with 10 features\n",
    "reg = linear_model.LinearRegression().fit(x_condo_NS_train_reg, y_condo_NS_train)\n",
    "condo_y_pred = reg.predict(x_condo_NS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_NS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_NS_train_reg, y_condo_NS_train)))\n",
    "\n",
    "condo_y_pred = reg.predict(x_condo_NS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_NS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_NS_test_reg, y_condo_NS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out all selected features\n",
    "x_condo_NS_train_reg = x_condo_NS_train[:, np.argsort(np.absolute(lasso_coef))[-36:]]\n",
    "x_condo_NS_test_reg = x_condo_NS_test[:, np.argsort(np.absolute(lasso_coef))[-36:]]\n",
    "x_columns = x_columns_all[np.argsort(np.absolute(lasso_coef))][-36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with all selected features\n",
    "reg = linear_model.LinearRegression().fit(x_condo_NS_train_reg, y_condo_NS_train)\n",
    "condo_y_pred = reg.predict(x_condo_NS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_NS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_NS_train_reg, y_condo_NS_train)))\n",
    "\n",
    "condo_y_pred = reg.predict(x_condo_NS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_NS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_NS_test_reg, y_condo_NS_test)))\n",
    "\n",
    "#reg_coef = reg.coef_\n",
    "#print(x_columns[np.argsort(np.absolute(reg_coef))])\n",
    "#print(np.sort(np.absolute(reg_coef)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(reg)\n",
    "\n",
    "visualizer.fit(x_condo_NS_train_reg, y_condo_NS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_condo_NS_test_reg, y_condo_NS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 Condominiums Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "MSE = []\n",
    "r2 = []\n",
    "complexity = []\n",
    "cost = []\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(x_condo_RS_train, y_condo_RS_train)\n",
    "    condo_y_pred = lasso.predict(x_condo_RS_test)\n",
    "    error = metrics.mean_squared_error(condo_y_pred, y_condo_RS_test)\n",
    "    MSE.append(error)\n",
    "    r2.append(lasso.score(x_condo_RS_test, y_condo_RS_test))\n",
    "    c = (np.linalg.norm(lasso.coef_, ord = 1))\n",
    "    complexity.append(c)\n",
    "    cost.append(error + (a*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE)\n",
    "plt.plot(range(5), MSE)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)\n",
    "plt.plot(range(5), r2)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity)\n",
    "plt.plot(range(5), complexity)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check variable importance for lasso regression\n",
    "lasso.set_params(alpha = 1)\n",
    "lasso.fit(x_condo_RS_train, y_condo_RS_train)\n",
    "lasso.predict(x_condo_RS_test)\n",
    "lasso_coef = lasso.coef_\n",
    "print(x_columns_all[np.argsort(np.absolute(lasso_coef))])\n",
    "print(np.sort(np.absolute(lasso_coef)))\n",
    "np.count_nonzero(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_condo_RS_train_reg = x_condo_RS_train[:, np.argsort(np.absolute(lasso_coef))[-10:]]\n",
    "x_condo_RS_test_reg = x_condo_RS_test[:, np.argsort(np.absolute(lasso_coef))[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "reg = linear_model.LinearRegression().fit(x_condo_RS_train_reg, y_condo_RS_train)\n",
    "condo_y_pred = reg.predict(x_condo_RS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_RS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_RS_train_reg, y_condo_RS_train)))\n",
    "\n",
    "condo_y_pred = reg.predict(x_condo_RS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_RS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_RS_test_reg, y_condo_RS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_condo_RS_train_reg = x_condo_RS_train[:, np.argsort(np.absolute(lasso_coef))[-51:]]\n",
    "x_condo_RS_test_reg = x_condo_RS_test[:, np.argsort(np.absolute(lasso_coef))[-51:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "reg = linear_model.LinearRegression().fit(x_condo_RS_train_reg, y_condo_RS_train)\n",
    "condo_y_pred = reg.predict(x_condo_RS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_RS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_RS_train_reg, y_condo_RS_train)))\n",
    "\n",
    "condo_y_pred = reg.predict(x_condo_RS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(condo_y_pred, y_condo_RS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_condo_RS_test_reg, y_condo_RS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(reg)\n",
    "\n",
    "visualizer.fit(x_condo_RS_train_reg, y_condo_RS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_condo_RS_test_reg, y_condo_RS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.6 Executive Condominiums New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "MSE = []\n",
    "r2 = []\n",
    "complexity = []\n",
    "cost = []\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(x_Econdo_NS_train, y_Econdo_NS_train)\n",
    "    Econdo_y_pred = lasso.predict(x_Econdo_NS_test)\n",
    "    error = metrics.mean_squared_error(Econdo_y_pred, y_Econdo_NS_test)\n",
    "    MSE.append(error)\n",
    "    r2.append(lasso.score(x_Econdo_NS_test, y_Econdo_NS_test))\n",
    "    c = (np.linalg.norm(lasso.coef_, ord = 1))\n",
    "    complexity.append(c)\n",
    "    cost.append(error + (a*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE)\n",
    "plt.plot(range(5), MSE)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)\n",
    "plt.plot(range(5), r2)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity)\n",
    "plt.plot(range(5), complexity)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check variable importance from lasso regression\n",
    "lasso.set_params(alpha = 1)\n",
    "lasso.fit(x_Econdo_NS_train, y_Econdo_NS_train)\n",
    "lasso.predict(x_Econdo_NS_test)\n",
    "lasso_coef = lasso.coef_\n",
    "print(x_columns_all[np.argsort(np.absolute(lasso_coef))])\n",
    "print(np.sort(np.absolute(lasso_coef)))\n",
    "np.count_nonzero(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out top 10 features\n",
    "x_Econdo_NS_train_reg = x_Econdo_NS_train[:, np.argsort(np.absolute(lasso_coef))[-10:]]\n",
    "x_Econdo_NS_test_reg = x_Econdo_NS_test[:, np.argsort(np.absolute(lasso_coef))[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with 10 features\n",
    "reg = linear_model.LinearRegression().fit(x_Econdo_NS_train_reg, y_Econdo_NS_train)\n",
    "Econdo_y_pred = reg.predict(x_Econdo_NS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_NS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_NS_train_reg, y_Econdo_NS_train)))\n",
    "\n",
    "Econdo_y_pred = reg.predict(x_Econdo_NS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_NS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_NS_test_reg, y_Econdo_NS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out all selected features\n",
    "x_Econdo_NS_train_reg = x_Econdo_NS_train[:, np.argsort(np.absolute(lasso_coef))[-15:]]\n",
    "x_Econdo_NS_test_reg = x_Econdo_NS_test[:, np.argsort(np.absolute(lasso_coef))[-15:]]\n",
    "x_columns = x_columns_all[np.argsort(np.absolute(lasso_coef))][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with all selected features\n",
    "reg = linear_model.LinearRegression().fit(x_Econdo_NS_train_reg, y_Econdo_NS_train)\n",
    "Econdo_y_pred = reg.predict(x_Econdo_NS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_NS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_NS_train_reg, y_Econdo_NS_train)))\n",
    "\n",
    "Econdo_y_pred = reg.predict(x_Econdo_NS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_NS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_NS_test_reg, y_Econdo_NS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(reg)\n",
    "\n",
    "visualizer.fit(x_Econdo_NS_train_reg, y_Econdo_NS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_Econdo_NS_test_reg, y_Econdo_NS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.7 Executive Condominiums Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "MSE = []\n",
    "r2 = []\n",
    "complexity = []\n",
    "cost = []\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(x_Econdo_RS_train, y_Econdo_RS_train)\n",
    "    Econdo_y_pred = lasso.predict(x_Econdo_RS_test)\n",
    "    error = metrics.mean_squared_error(Econdo_y_pred, y_Econdo_RS_test)\n",
    "    MSE.append(error)\n",
    "    r2.append(lasso.score(x_Econdo_RS_test, y_Econdo_RS_test))\n",
    "    c = (np.linalg.norm(lasso.coef_, ord = 1))\n",
    "    complexity.append(c)\n",
    "    cost.append(error + (a*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE)\n",
    "plt.plot(range(5), MSE)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)\n",
    "plt.plot(range(5), r2)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity)\n",
    "plt.plot(range(5), complexity)\n",
    "plt.xticks(np.arange(5), alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check variable importance for lasso regression\n",
    "lasso.set_params(alpha = 1)\n",
    "lasso.fit(x_Econdo_RS_train, y_Econdo_RS_train)\n",
    "lasso.predict(x_Econdo_RS_test)\n",
    "lasso_coef = lasso.coef_\n",
    "print(x_columns_all[np.argsort(np.absolute(lasso_coef))])\n",
    "print(np.sort(np.absolute(lasso_coef)))\n",
    "np.count_nonzero(lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Econdo_RS_train_reg = x_Econdo_RS_train[:, np.argsort(np.absolute(lasso_coef))[-10:]]\n",
    "x_Econdo_RS_test_reg = x_Econdo_RS_test[:, np.argsort(np.absolute(lasso_coef))[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "reg = linear_model.LinearRegression().fit(x_Econdo_RS_train_reg, y_Econdo_RS_train)\n",
    "Econdo_y_pred = reg.predict(x_Econdo_RS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_RS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_RS_train_reg, y_Econdo_RS_train)))\n",
    "\n",
    "Econdo_y_pred = reg.predict(x_Econdo_RS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_RS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_RS_test_reg, y_Econdo_RS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Econdo_RS_train_reg = x_Econdo_RS_train[:, np.argsort(np.absolute(lasso_coef))[-16:]]\n",
    "x_Econdo_RS_test_reg = x_Econdo_RS_test[:, np.argsort(np.absolute(lasso_coef))[-16:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "reg = linear_model.LinearRegression().fit(x_Econdo_RS_train_reg, y_Econdo_RS_train)\n",
    "Econdo_y_pred = reg.predict(x_Econdo_RS_train_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_RS_train)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_RS_train_reg, y_Econdo_RS_train)))\n",
    "\n",
    "Econdo_y_pred = reg.predict(x_Econdo_RS_test_reg)\n",
    "print(\"MSE: \" \n",
    "      + str(metrics.mean_squared_error(Econdo_y_pred, y_Econdo_RS_test)) \n",
    "      + \"\\nR^2: \" \n",
    "      + str(reg.score(x_Econdo_RS_test_reg, y_Econdo_RS_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(reg)\n",
    "\n",
    "visualizer.fit(x_Econdo_RS_train_reg, y_Econdo_RS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_Econdo_RS_test_reg, y_Econdo_RS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_apart_NS_train = x_apart_NS_train_original\n",
    "x_apart_NS_test = x_apart_NS_test_original\n",
    "\n",
    "x_apart_RS_train =x_apart_RS_train_original\n",
    "x_apart_RS_test =x_apart_RS_test_original\n",
    "\n",
    "x_condo_NS_train =x_condo_NS_train_original\n",
    "x_condo_NS_test =x_condo_NS_test_orinigal\n",
    "\n",
    "x_condo_RS_train =x_condo_RS_train_original\n",
    "x_condo_RS_test =x_condo_RS_test_original\n",
    "\n",
    "x_Econdo_NS_train =x_Econdo_NS_train_orinigal\n",
    "x_Econdo_NS_test =x_Econdo_NS_test_original\n",
    "\n",
    "x_Econdo_RS_train =x_Econdo_RS_train_original\n",
    "x_Econdo_RS_test =x_Econdo_RS_test_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Apartment New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(x_apart_NS_train,y_apart_NS_train)\n",
    "\n",
    "R_Square = regressor.score(x_apart_NS_test,y_apart_NS_test)\n",
    "print(\"The R square is :\", R_Square)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_importance = regressor.feature_importances_\n",
    "all_features = list(x_apart_NS_train)\n",
    "m,n = x_apart_NS_train.shape\n",
    "\n",
    "    \n",
    "Important_Features = pd.DataFrame(columns = [\"Feature\",\"Importance\"])\n",
    "\n",
    "for i in range(n):\n",
    "    Important_Features.loc[i] = [all_features[i], feature_importance[i]] \n",
    "\n",
    "\n",
    "\n",
    "Important_Features_sorted = Important_Features.sort_values('Importance',ascending=False) \n",
    "Important_Features_sorted.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_apart_NS_test, regressor.predict(x_apart_NS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Apartment Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=0,min_samples_split=20)\n",
    "regressor.fit(x_apart_RS_train,y_apart_RS_train)\n",
    "\n",
    "R_Square = regressor.score(x_apart_RS_test,y_apart_RS_test)\n",
    "print(\"The R square is :\", R_Square)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_importance = regressor.feature_importances_\n",
    "all_features = list(x_apart_RS_train)\n",
    "m,n = x_apart_RS_train.shape\n",
    "\n",
    "    \n",
    "Important_Features = pd.DataFrame(columns = [\"Feature\",\"Importance\"])\n",
    "\n",
    "for i in range(n):\n",
    "    Important_Features.loc[i] = [all_features[i], feature_importance[i]] \n",
    "\n",
    "\n",
    "\n",
    "Important_Features_sorted = Important_Features.sort_values('Importance',ascending=False) \n",
    "Important_Features_sorted.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_apart_RS_test, regressor.predict(x_apart_RS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 Condo New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(x_condo_NS_train,y_condo_NS_train)\n",
    "\n",
    "R_Square = regressor.score(x_condo_NS_test,y_condo_NS_test)\n",
    "print(\"The R square is :\", R_Square)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_importance = regressor.feature_importances_\n",
    "all_features = list(x_condo_NS_train)\n",
    "m,n = x_condo_NS_train.shape\n",
    "\n",
    "    \n",
    "Important_Features = pd.DataFrame(columns = [\"Feature\",\"Importance\"])\n",
    "\n",
    "for i in range(n):\n",
    "    Important_Features.loc[i] = [all_features[i], feature_importance[i]] \n",
    "\n",
    "\n",
    "\n",
    "Important_Features_sorted = Important_Features.sort_values('Importance',ascending=False) \n",
    "Important_Features_sorted.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_condo_NS_test, regressor.predict(x_condo_NS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 Condo Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=0,min_samples_split=30)\n",
    "regressor.fit(x_condo_RS_train,y_condo_RS_train)\n",
    "\n",
    "R_Square = regressor.score(x_condo_RS_test,y_condo_RS_test)\n",
    "print(\"The R square is :\", R_Square)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_importance = regressor.feature_importances_\n",
    "all_features = list(x_condo_RS_train)\n",
    "m,n = x_condo_RS_train.shape\n",
    "\n",
    "    \n",
    "Important_Features = pd.DataFrame(columns = [\"Feature\",\"Importance\"])\n",
    "\n",
    "for i in range(n):\n",
    "    Important_Features.loc[i] = [all_features[i], feature_importance[i]] \n",
    "\n",
    "\n",
    "\n",
    "Important_Features_sorted = Important_Features.sort_values('Importance',ascending=False) \n",
    "Important_Features_sorted.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_condo_RS_test, regressor.predict(x_condo_RS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 Econdo New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=0,min_samples_split=20)\n",
    "regressor.fit(x_Econdo_NS_train,y_Econdo_NS_train)\n",
    "\n",
    "R_Square = regressor.score(x_Econdo_NS_test,y_Econdo_NS_test)\n",
    "print(\"The R square is :\", R_Square)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_importance = regressor.feature_importances_\n",
    "all_features = list(x_Econdo_NS_train)\n",
    "m,n = x_Econdo_NS_train.shape\n",
    "\n",
    "    \n",
    "Important_Features = pd.DataFrame(columns = [\"Feature\",\"Importance\"])\n",
    "\n",
    "for i in range(n):\n",
    "    Important_Features.loc[i] = [all_features[i], feature_importance[i]] \n",
    "\n",
    "\n",
    "\n",
    "Important_Features_sorted = Important_Features.sort_values('Importance',ascending=False) \n",
    "Important_Features_sorted.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_Econdo_NS_test, regressor.predict(x_Econdo_NS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 Econdo Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=0,min_samples_split=30)\n",
    "regressor.fit(x_Econdo_RS_train,y_Econdo_RS_train)\n",
    "\n",
    "R_Square = regressor.score(x_Econdo_RS_test,y_Econdo_RS_test)\n",
    "print(\"The R square is :\", R_Square)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_importance = regressor.feature_importances_\n",
    "all_features = list(x_Econdo_RS_train)\n",
    "m,n = x_Econdo_RS_train.shape\n",
    "\n",
    "    \n",
    "Important_Features = pd.DataFrame(columns = [\"Feature\",\"Importance\"])\n",
    "\n",
    "for i in range(n):\n",
    "    Important_Features.loc[i] = [all_features[i], feature_importance[i]] \n",
    "\n",
    "\n",
    "\n",
    "Important_Features_sorted = Important_Features.sort_values('Importance',ascending=False) \n",
    "Important_Features_sorted.iloc[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_Econdo_RS_test, regressor.predict(x_Econdo_RS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Apartment New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_apart_NS = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=2, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "regr_apart_NS.fit(x_apart_NS_train, y_apart_NS_train)\n",
    "\n",
    "\n",
    "print(\"R2 squared for test\")\n",
    "print(regr_apart_NS.score(x_apart_NS_test, y_apart_NS_test, sample_weight=None))\n",
    "\n",
    "print(\"R2 squared for train\")\n",
    "print(regr_apart_NS.score(x_apart_NS_train, y_apart_NS_train, sample_weight=None))\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_apart_NS_test,regr_apart_NS.predict(x_apart_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_apart_NS_train,regr_apart_NS.predict(x_apart_NS_train)))\n",
    "\n",
    "importances = regr_apart_NS.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr_apart_NS.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "names = x_apart_NS_train.columns\n",
    "print (sorted(zip(map(lambda z: round(z, 4), regr_apart_NS.feature_importances_), names), \n",
    "             reverse=True))\n",
    "\n",
    "\n",
    "visualizer = PredictionError(regr_apart_NS)\n",
    "visualizer.fit(x_apart_NS_train, y_apart_NS_train)  \n",
    "visualizer.score(x_apart_NS_test, y_apart_NS_test)  \n",
    "g = visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 Apartment Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_apart_RS = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=2, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "regr_apart_RS.fit(x_apart_RS_train, y_apart_RS_train)\n",
    "\n",
    "\n",
    "print(\"R2 squared for test\")\n",
    "print(regr_apart_RS.score(x_apart_RS_test, y_apart_RS_test, sample_weight=None))\n",
    "\n",
    "print(\"R2 squared for train\")\n",
    "print(regr_apart_RS.score(x_apart_RS_train, y_apart_RS_train, sample_weight=None))\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_apart_RS_test,regr_apart_RS.predict(x_apart_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_apart_RS_train,regr_apart_RS.predict(x_apart_RS_train)))\n",
    "\n",
    "importances = regr_apart_RS.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr_apart_RS.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "names = x_apart_RS_train.columns\n",
    "print (sorted(zip(map(lambda z: round(z, 4), regr_apart_RS.feature_importances_), names), \n",
    "             reverse=True))\n",
    "\n",
    "visualizer = PredictionError(regr_apart_RS)\n",
    "visualizer.fit(x_apart_RS_train, y_apart_RS_train)  \n",
    "visualizer.score(x_apart_RS_test, y_apart_RS_test)  \n",
    "g = visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 Condo New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_condo_NS = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=2, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "regr_condo_NS.fit(x_condo_NS_train, y_condo_NS_train)\n",
    "\n",
    "\n",
    "print(\"R2 squared for test\")\n",
    "print(regr_condo_NS.score(x_condo_NS_test, y_condo_NS_test, sample_weight=None))\n",
    "\n",
    "print(\"R2 squared for train\")\n",
    "print(regr_condo_NS.score(x_condo_NS_train, y_condo_NS_train, sample_weight=None))\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_condo_NS_test,regr_condo_NS.predict(x_condo_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_condo_NS_train,regr_condo_NS.predict(x_condo_NS_train)))\n",
    "\n",
    "importances = regr_condo_NS.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr_condo_NS.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "names = x_condo_NS_train.columns\n",
    "print (sorted(zip(map(lambda z: round(z, 4), regr_condo_NS.feature_importances_), names), \n",
    "             reverse=True))\n",
    "\n",
    "visualizer = PredictionError(regr_condo_NS)\n",
    "visualizer.fit(x_condo_NS_train, y_condo_NS_train)  \n",
    "visualizer.score(x_condo_NS_test, y_condo_NS_test)  \n",
    "g = visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4 Condo Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_condo_RS = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=2, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "regr_condo_RS.fit(x_condo_RS_train, y_condo_RS_train)\n",
    "\n",
    "\n",
    "print(\"R2 squared for test\")\n",
    "print(regr_condo_RS.score(x_condo_RS_test, y_condo_RS_test, sample_weight=None))\n",
    "\n",
    "print(\"R2 squared for train\")\n",
    "print(regr_condo_RS.score(x_condo_RS_train, y_condo_RS_train, sample_weight=None))\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_condo_RS_test,regr_condo_RS.predict(x_condo_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_condo_RS_train,regr_condo_RS.predict(x_condo_RS_train)))\n",
    "\n",
    "importances = regr_condo_RS.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr_condo_RS.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "names = x_condo_RS_train.columns\n",
    "print (sorted(zip(map(lambda z: round(z, 4), regr_condo_RS.feature_importances_), names), \n",
    "             reverse=True))\n",
    "\n",
    "visualizer = PredictionError(regr_condo_RS)\n",
    "visualizer.fit(x_condo_RS_train, y_condo_RS_train)  \n",
    "visualizer.score(x_condo_RS_test, y_condo_RS_test)  \n",
    "g = visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.5 Executive Condo New Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_Econdo_NS = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=2, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "regr_Econdo_NS.fit(x_Econdo_NS_train, y_Econdo_NS_train)\n",
    "\n",
    "\n",
    "print(\"R2 squared for test\")\n",
    "print(regr_Econdo_NS.score(x_Econdo_NS_test, y_Econdo_NS_test, sample_weight=None))\n",
    "\n",
    "print(\"R2 squared for train\")\n",
    "print(regr_Econdo_NS.score(x_Econdo_NS_train, y_Econdo_NS_train, sample_weight=None))\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_Econdo_NS_test,regr_Econdo_NS.predict(x_Econdo_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_Econdo_NS_train,regr_Econdo_NS.predict(x_Econdo_NS_train)))\n",
    "\n",
    "importances = regr_Econdo_NS.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr_Econdo_NS.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "names = x_Econdo_NS_train.columns\n",
    "print (sorted(zip(map(lambda z: round(z, 4), regr_Econdo_NS.feature_importances_), names), \n",
    "             reverse=True))\n",
    "\n",
    "visualizer = PredictionError(regr_Econdo_NS)\n",
    "visualizer.fit(x_Econdo_NS_train, y_Econdo_NS_train)  \n",
    "visualizer.score(x_Econdo_NS_test, y_Econdo_NS_test)  \n",
    "g = visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.6 Executive Condo  Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_Econdo_RS = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=2, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, \n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "regr_Econdo_RS.fit(x_Econdo_RS_train, y_Econdo_RS_train)\n",
    "\n",
    "\n",
    "print(\"R2 squared for test\")\n",
    "print(regr_Econdo_RS.score(x_Econdo_RS_test, y_Econdo_RS_test, sample_weight=None))\n",
    "\n",
    "print(\"R2 squared for train\")\n",
    "print(regr_Econdo_RS.score(x_Econdo_RS_train, y_Econdo_RS_train, sample_weight=None))\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_Econdo_RS_test,regr_Econdo_RS.predict(x_Econdo_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_Econdo_RS_train,regr_Econdo_RS.predict(x_Econdo_RS_train)))\n",
    "\n",
    "importances = regr_Econdo_RS.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr_Econdo_RS.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "names = x_Econdo_RS_train.columns\n",
    "print (sorted(zip(map(lambda z: round(z, 4), regr_Econdo_RS.feature_importances_), names), \n",
    "             reverse=True))\n",
    "\n",
    "visualizer = PredictionError(regr_Econdo_RS)\n",
    "visualizer.fit(x_Econdo_RS_train, y_Econdo_RS_train)  \n",
    "visualizer.score(x_Econdo_RS_test, y_Econdo_RS_test)  \n",
    "g = visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Boosting - GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1.parasite_axes import host_subplot\n",
    "from mpl_toolkits.axisartist.axislines import Axes\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm.classes import NuSVR\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 Apartment New Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fm\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': gbr,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [100, 1000, 2000, 4000, 6000, 8000, 10000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_apart_NS_train,\n",
    "     'y_train': y_apart_NS_train,\n",
    "     'x_test': x_apart_NS_test,\n",
    "     'y_test': y_apart_NS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_apart_NS = ensemble.GradientBoostingRegressor(n_estimators=8000)\n",
    "\n",
    "gbr_apart_NS.fit(x_apart_NS_train, y_apart_NS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", gbr_apart_NS.score(x_apart_NS_test, y_apart_NS_test, sample_weight=None))\n",
    "print(\"R2 for train\", gbr_apart_NS.score(x_apart_NS_train, y_apart_NS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_apart_NS_test,gbr_apart_NS.predict(x_apart_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_apart_NS_train,gbr_apart_NS.predict(x_apart_NS_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_apart_NS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), gbr_apart_NS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 Apartment Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': gbr,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [200,400,600,800,1000,1200],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_apart_RS_train,\n",
    "     'y_train': y_apart_RS_train,\n",
    "     'x_test': x_apart_RS_test,\n",
    "     'y_test': y_apart_RS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_apart_RS = ensemble.GradientBoostingRegressor(n_estimators=800)\n",
    "\n",
    "gbr_apart_RS.fit(x_apart_RS_train, y_apart_RS_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", gbr_apart_RS.score(x_apart_RS_test, y_apart_RS_test, sample_weight=None))\n",
    "print(\"R2 for train\", gbr_apart_RS.score(x_apart_RS_train, y_apart_RS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_apart_RS_test,gbr_apart_RS.predict(x_apart_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_apart_RS_train,gbr_apart_RS.predict(x_apart_RS_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_apart_RS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), gbr_apart_RS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 Condo New Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': gbr,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [100, 1000, 2000, 4000, 6000, 8000, 10000, 12000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_condo_NS_train,\n",
    "     'y_train': y_condo_NS_train,\n",
    "     'x_test': x_condo_NS_test,\n",
    "     'y_test': y_condo_NS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_condo_NS = ensemble.GradientBoostingRegressor(n_estimators=10000)\n",
    "\n",
    "gbr_condo_NS.fit(x_condo_NS_train, y_condo_NS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", gbr_condo_NS.score(x_condo_NS_test, y_condo_NS_test, sample_weight=None))\n",
    "print(\"R2 for train\", gbr_condo_NS.score(x_condo_NS_train, y_condo_NS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_condo_NS_test,gbr_condo_NS.predict(x_condo_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_condo_NS_train,gbr_condo_NS.predict(x_condo_NS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_condo_NS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), gbr_condo_NS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 Condo Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': gbr,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [1000,3000,5000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_condo_RS_train,\n",
    "     'y_train': y_condo_RS_train,\n",
    "     'x_test': x_condo_RS_test,\n",
    "     'y_test': y_condo_RS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_condo_RS = ensemble.GradientBoostingRegressor(n_estimators=3000)\n",
    "\n",
    "gbr_condo_RS.fit(x_condo_RS_train, y_condo_RS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", gbr_condo_RS.score(x_condo_RS_test, y_condo_RS_test, sample_weight=None))\n",
    "print(\"R2 for train\", gbr_condo_RS.score(x_condo_RS_train, y_condo_RS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_condo_RS_test,gbr_condo_RS.predict(x_condo_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_condo_RS_train,gbr_condo_RS.predict(x_condo_RS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_condo_RS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), gbr_condo_RS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.5 Econdo New Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': gbr,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [1000,3000,5000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_Econdo_NS_train,\n",
    "     'y_train': y_Econdo_NS_train,\n",
    "     'x_test': x_Econdo_NS_test,\n",
    "     'y_test': y_Econdo_NS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_Econdo_NS = ensemble.GradientBoostingRegressor(n_estimators=3000)\n",
    "\n",
    "gbr_Econdo_NS.fit(x_Econdo_NS_train, y_Econdo_NS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", gbr_Econdo_NS.score(x_Econdo_NS_test, y_Econdo_NS_test, sample_weight=None))\n",
    "print(\"R2 for train\", gbr_Econdo_NS.score(x_Econdo_NS_train, y_Econdo_NS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_Econdo_NS_test,gbr_Econdo_NS.predict(x_Econdo_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_Econdo_NS_train,gbr_Econdo_NS.predict(x_Econdo_NS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_Econdo_NS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), gbr_Econdo_NS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.6 Econdo Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': gbr,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [140,160,180,200,220,240,260,280,300],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_Econdo_RS_train,\n",
    "     'y_train': y_Econdo_RS_train,\n",
    "     'x_test': x_Econdo_RS_test,\n",
    "     'y_test': y_Econdo_RS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_Econdo_RS = ensemble.GradientBoostingRegressor(n_estimators=220)\n",
    "\n",
    "gbr_Econdo_RS.fit(x_Econdo_RS_train, y_Econdo_RS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", gbr_Econdo_RS.score(x_Econdo_RS_test, y_Econdo_RS_test, sample_weight=None))\n",
    "print(\"R2 for train\", gbr_Econdo_RS.score(x_Econdo_RS_train, y_Econdo_RS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_Econdo_RS_test,gbr_Econdo_RS.predict(x_Econdo_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_Econdo_RS_train,gbr_Econdo_RS.predict(x_Econdo_RS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_Econdo_RS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), gbr_Econdo_RS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Boosting - XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5.1 Apartment New Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': xgb.XGBRegressor,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [2000,2200,2400,2600,2800,3000,3200,3400,3600,3800,4000,4200],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_apart_NS_train,\n",
    "     'y_train': y_apart_NS_train,\n",
    "     'x_test': x_apart_NS_test,\n",
    "     'y_test': y_apart_NS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_apart_NS = xgb.XGBRegressor(n_estimators = 3600)\n",
    "\n",
    "xg_reg_apart_NS.fit(x_apart_NS_train, y_apart_NS_train)\n",
    "\n",
    "preds_apart_NS = xg_reg_apart_NS.predict(x_apart_NS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", xg_reg_apart_NS.score(x_apart_NS_test, y_apart_NS_test, sample_weight=None))\n",
    "print(\"R2 for train\", xg_reg_apart_NS.score(x_apart_NS_train, y_apart_NS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_apart_NS_test,xg_reg_apart_NS.predict(x_apart_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_apart_NS_train,xg_reg_apart_NS.predict(x_apart_NS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_apart_NS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), xg_reg_apart_NS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2 Apartment Resale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': xgb.XGBRegressor,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_apart_RS_train,\n",
    "     'y_train': y_apart_RS_train,\n",
    "     'x_test': x_apart_RS_test,\n",
    "     'y_test': y_apart_RS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_apart_RS = xgb.XGBRegressor(n_estimators = 600)\n",
    "\n",
    "xg_reg_apart_RS.fit(x_apart_RS_train, y_apart_RS_train)\n",
    "\n",
    "preds_apart_RS = xg_reg_apart_RS.predict(x_apart_RS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", xg_reg_apart_RS.score(x_apart_RS_test, y_apart_RS_test, sample_weight=None))\n",
    "print(\"R2 for train\", xg_reg_apart_RS.score(x_apart_RS_train, y_apart_RS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_apart_RS_test,xg_reg_apart_RS.predict(x_apart_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_apart_RS_train,xg_reg_apart_RS.predict(x_apart_RS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_apart_RS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), xg_reg_apart_RS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7.5.3 Condo - New Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': xgb.XGBRegressor,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [100, 1000, 2000, 4000, 6000, 8000, 10000, 12000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_condo_NS_train,\n",
    "     'y_train': y_condo_NS_train,\n",
    "     'x_test': x_condo_NS_test,\n",
    "     'y_test': y_condo_NS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_condo_NS = xgb.XGBRegressor(n_estimators = 8000)\n",
    "\n",
    "xg_reg_condo_NS.fit(x_condo_NS_train, y_condo_NS_train)\n",
    "\n",
    "preds_condo_NS = xg_reg_condo_NS.predict(x_condo_NS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", xg_reg_condo_NS.score(x_condo_NS_test, y_condo_NS_test, sample_weight=None))\n",
    "print(\"R2 for train\", xg_reg_condo_NS.score(x_condo_NS_train, y_condo_NS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_condo_NS_test,xg_reg_condo_NS.predict(x_condo_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_condo_NS_train,xg_reg_condo_NS.predict(x_condo_NS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_condo_NS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), xg_reg_condo_NS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.4 Condo - Resales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': xgb.XGBRegressor,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [100, 1000, 2000, 4000, 6000, 8000, 10000, 12000, 14000],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_condo_RS_train,\n",
    "     'y_train': y_condo_RS_train,\n",
    "     'x_test': x_condo_RS_test,\n",
    "     'y_test': y_condo_RS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_condo_RS = xgb.XGBRegressor(n_estimators = 2000)\n",
    "\n",
    "xg_reg_condo_RS.fit(x_condo_RS_train, y_condo_RS_train)\n",
    "\n",
    "preds_condo_RS = xg_reg_condo_RS.predict(x_condo_RS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", xg_reg_condo_RS.score(x_condo_RS_test, y_condo_RS_test, sample_weight=None))\n",
    "print(\"R2 for train\", xg_reg_condo_RS.score(x_condo_RS_train, y_condo_RS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_condo_RS_test,xg_reg_condo_RS.predict(x_condo_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_condo_RS_train,xg_reg_condo_RS.predict(x_condo_RS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_condo_RS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), xg_reg_condo_RS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.5 ECondo - New Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': xgb.XGBRegressor,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [100, 500, 1000, 1500, 2000, 2500, 3000, 3500],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_Econdo_NS_train,\n",
    "     'y_train': y_Econdo_NS_train,\n",
    "     'x_test': x_Econdo_NS_test,\n",
    "     'y_test': y_Econdo_NS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_Econdo_NS = xgb.XGBRegressor(n_estimators = 3000)\n",
    "\n",
    "xg_reg_Econdo_NS.fit(x_Econdo_NS_train, y_Econdo_NS_train)\n",
    "\n",
    "preds_Econdo_NS = xg_reg_Econdo_NS.predict(x_Econdo_NS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", xg_reg_Econdo_NS.score(x_Econdo_NS_test, y_Econdo_NS_test, sample_weight=None))\n",
    "print(\"R2 for train\", xg_reg_Econdo_NS.score(x_Econdo_NS_train, y_Econdo_NS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_Econdo_NS_test,xg_reg_Econdo_NS.predict(x_Econdo_NS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_Econdo_NS_train,xg_reg_Econdo_NS.predict(x_Econdo_NS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_Econdo_NS_train.columns\n",
    "\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), xg_reg_Econdo_NS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.6 ECondo - Resales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_influence(conf):\n",
    "    \"\"\"\n",
    "    Benchmark influence of :changing_param: on both MSE and latency.\n",
    "    \"\"\"\n",
    "    prediction_times = []\n",
    "    prediction_powers = []\n",
    "    complexities = []\n",
    "    for param_value in conf['changing_param_values']:\n",
    "        conf['tuned_params'][conf['changing_param']] = param_value\n",
    "        estimator = conf['estimator'](**conf['tuned_params'])\n",
    "        print(\"Benchmarking %s\" % estimator)\n",
    "        estimator.fit(conf['x_train'], conf['y_train'])\n",
    "        conf['postfit_hook'](estimator)\n",
    "        complexity = conf['complexity_computer'](estimator)\n",
    "        complexities.append(complexity)\n",
    "        start_time = time.time()\n",
    "        y_pred = estimator.predict(conf['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](\n",
    "            conf['y_test'], y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity: %d | %s: %.4f | Pred. Time: %fs\\n\" % (\n",
    "            complexity, conf['prediction_performance_label'], pred_score,\n",
    "            elapsed_time))\n",
    "    return prediction_powers, prediction_times, complexities\n",
    "\n",
    "\n",
    "def plot_influence(conf, mse_values, prediction_times, complexities):\n",
    "    \"\"\"\n",
    "    Plot influence of model complexity on both accuracy and latency.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    host = host_subplot(111, axes_class=Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    host.set_xlabel('Model Complexity (%s)' % conf['complexity_label'])\n",
    "    y1_label = conf['prediction_performance_label']\n",
    "    y2_label = \"Time (s)\"\n",
    "    host.set_ylabel(y1_label)\n",
    "    par1.set_ylabel(y2_label)\n",
    "    p1, = host.plot(complexities, mse_values, 'b-', label=\"prediction error\")\n",
    "    p2, = par1.plot(complexities, prediction_times, 'r-',\n",
    "                    label=\"latency\")\n",
    "    host.legend(loc='upper right')\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    par1.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    plt.title('Influence of Model Complexity - %s' % conf['estimator'].__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _count_nonzero_coefficients(estimator):\n",
    "    a = estimator.coef_.toarray()\n",
    "    return np.count_nonzero(a)\n",
    "\n",
    "configurations = [\n",
    "    {'estimator': xgb.XGBRegressor,\n",
    "     'tuned_params': {'loss': 'ls'},\n",
    "     'changing_param': 'n_estimators',\n",
    "     'changing_param_values': [60,80,100,120,140,160,180,200,220,240,260,280,300],\n",
    "     'complexity_label': 'n_trees',\n",
    "     'complexity_computer': lambda x: x.n_estimators,\n",
    "     'x_train': x_Econdo_RS_train,\n",
    "     'y_train': y_Econdo_RS_train,\n",
    "     'x_test': x_Econdo_RS_test,\n",
    "     'y_test': y_Econdo_RS_test,\n",
    "     'postfit_hook': lambda x: x,\n",
    "     'prediction_performance_computer': mean_squared_error,\n",
    "     'prediction_performance_label': 'MSE'},\n",
    "]\n",
    "for conf in configurations:\n",
    "    prediction_performances, prediction_times, complexities = \\\n",
    "        benchmark_influence(conf)\n",
    "    plot_influence(conf, prediction_performances, prediction_times,\n",
    "                   complexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_Econdo_RS = xgb.XGBRegressor(n_estimators = 260)\n",
    "\n",
    "xg_reg_Econdo_RS.fit(x_Econdo_RS_train, y_Econdo_RS_train)\n",
    "\n",
    "preds_Econdo_RS = xg_reg_Econdo_RS.predict(x_Econdo_RS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 for test\", xg_reg_Econdo_RS.score(x_Econdo_RS_test, y_Econdo_RS_test, sample_weight=None))\n",
    "print(\"R2 for train\", xg_reg_Econdo_RS.score(x_Econdo_RS_train, y_Econdo_RS_train, sample_weight=None))\n",
    "\n",
    "print(\"MSE Test\",metrics.mean_squared_error(y_Econdo_RS_test,xg_reg_Econdo_RS.predict(x_Econdo_RS_test)))\n",
    "print(\"MSE Train\",metrics.mean_squared_error(y_Econdo_RS_train,xg_reg_Econdo_RS.predict(x_Econdo_RS_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = x_Econdo_RS_train.columns\n",
    "columns = [\"Importance\", \"Feature Name\"]\n",
    "index = [\"1st Important Feature\", \n",
    "         \"2nd Important Feature\", \n",
    "         \"3rd Important Feature\", \n",
    "         \"4th Important Feature\", \n",
    "         \"5th Important Feature\",\n",
    "        \"6th Important Feature\",\n",
    "        \"7th Important Feature\",\n",
    "        \"8th Important Feature\",\n",
    "        \"9th Important Feature\",\n",
    "        \"10th Important Feature\"]\n",
    "\n",
    "pd.DataFrame(sorted(zip(map(lambda z: round(z, 4), xg_reg_Econdo_RS.feature_importances_), names), \n",
    "             reverse=True)[0:10], columns = columns, index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Discussion on Overall Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the predictive models employed for eac.h domain, we can deduce that XGBRegressor is generally the best performing model where it achieved the highest R2 score and lowest MSE score for all domains.\n",
    "\n",
    "To determine how well the models fit the data, we need to take a statistical measure of how close each data point fits the regression line. By taking XGBRegressor from the Apartment â€“ New Sales and Resales domains as an example, we can visualize its goodness-of-fit as shown in the diagrams below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(xg_reg_apart_NS)\n",
    "\n",
    "visualizer.fit(x_apart_NS_train, y_apart_NS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_apart_NS_test, y_apart_NS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "#lasso = Lasso()\n",
    "visualizer = PredictionError(xg_reg_apart_RS)\n",
    "\n",
    "visualizer.fit(x_apart_RS_train, y_apart_RS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_apart_RS_test, y_apart_RS_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the higher the R2, the better the model fits the data. However, the measurement of R2 alone is not sufficient to determine biasness of the predictions. In order to do so, we employed the use of residual plots to analyse the variance of error. A random dispersion of data points around the horizontal axis tells us that our model is performing well. Additionally, from the histogram on the right, we can also see that the error is normally distributed around zero, providing another indication of a well fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "visualizer = ResidualsPlot(xg_reg_apart_NS)\n",
    "\n",
    "visualizer.fit(x_apart_NS_train, y_apart_NS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_apart_NS_test, y_apart_NS_test)  # Evaluate the model on the test data\n",
    "visualizer.poof()                 # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "visualizer = ResidualsPlot(xg_reg_apart_RS)\n",
    "\n",
    "visualizer.fit(x_apart_NS_train, y_apart_NS_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_apart_NS_test, y_apart_NS_test)  # Evaluate the model on the test data\n",
    "visualizer.poof()                 # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 Discussion on Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Overall Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, we can see that both Area (sqf) and Floor No (Final) consistently appear throughout with a relatively high importance score. However, in order to truly understand how these features affect our target variable, we aim to visualize these relationships to gain further insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1 Area (sqf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2,ncols=3)\n",
    "fig.set_size_inches(20, 10)\n",
    "sns.regplot(x=x_apart_NS[\"Area (sqf)\"], y=y_apart_NS,ax=axes[0][0])\n",
    "sns.regplot(x=x_condo_NS[\"Area (sqf)\"], y=y_condo_NS,ax=axes[0][1])\n",
    "sns.regplot(x=x_Econdo_NS[\"Area (sqf)\"], y=y_Econdo_NS,ax=axes[0][2])\n",
    "sns.regplot(x=x_apart_RS[\"Area (sqf)\"], y=y_apart_RS,ax=axes[1][0])\n",
    "sns.regplot(x=x_condo_RS[\"Area (sqf)\"], y=y_condo_RS,ax=axes[1][1])\n",
    "sns.regplot(x=x_Econdo_RS[\"Area (sqf)\"], y=y_Econdo_RS,ax=axes[1][2])\n",
    "\n",
    "\n",
    "axes[0][0].set(xlabel='Area (sqf)', ylabel='Unit Price ($psf)',title=\"Reg Plot Of Unit Price ($psf) Against Area (sqf) for Apartment New Sales\")\n",
    "axes[0][1].set(xlabel='Area (sqf)', ylabel='Unit Price ($psf)',title=\"Reg Plot Of Unit Price ($psf) Against Area (sqf) for Condo New Sales\")\n",
    "axes[0][2].set(xlabel='Area (sqf)', ylabel='Unit Price ($psf)',title=\"Reg Plot Of Unit Price ($psf) Against Area (sqf) for Executive Condo New Sales\")\n",
    "axes[1][0].set(xlabel='Area (sqf)', ylabel='Unit Price ($psf)',title=\"Reg Plot Of Unit Price ($psf) Against Area (sqf) for Apartment Resales\")\n",
    "axes[1][1].set(xlabel='Area (sqf)', ylabel='Unit Price ($psf)',title=\"Reg Plot Of Unit Price ($psf) Against Area (sqf) for Condo Resales\")\n",
    "axes[1][2].set(xlabel='Area (sqf)', ylabel='Unit Price ($psf)',title=\"Reg Plot Of Unit Price ($psf) Against Area (sqf) for Executive Condo Resales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 Floor No (Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2,ncols=3)\n",
    "fig.set_size_inches(20, 10)\n",
    "sns.boxplot(x=x_apart_NS[\"Floor No (Final)\"], y=y_apart_NS,ax=axes[0][0])\n",
    "sns.regplot(x=x_apart_NS[\"Floor No (Final)\"], y=y_apart_NS, scatter=False, ax=axes[0][0])\n",
    "\n",
    "sns.boxplot(x=x_condo_NS[\"Floor No (Final)\"], y=y_condo_NS,ax=axes[0][1])\n",
    "sns.regplot(x=x_condo_NS[\"Floor No (Final)\"], y=y_condo_NS, scatter = False, ax=axes[0][1])\n",
    "\n",
    "sns.boxplot(x=x_Econdo_NS[\"Floor No (Final)\"], y=y_Econdo_NS,ax=axes[0][2])\n",
    "sns.regplot(x=x_Econdo_NS[\"Floor No (Final)\"], y=y_Econdo_NS,scatter = False,ax=axes[0][2])\n",
    "\n",
    "sns.boxplot(x=x_apart_RS[\"Floor No (Final)\"], y=y_apart_RS,ax=axes[1][0])\n",
    "sns.regplot(x=x_apart_RS[\"Floor No (Final)\"], y=y_apart_RS, scatter = False, ax=axes[1][0])\n",
    "\n",
    "sns.boxplot(x=x_condo_RS[\"Floor No (Final)\"], y=y_condo_RS,ax=axes[1][1])\n",
    "sns.regplot(x=x_condo_RS[\"Floor No (Final)\"], y=y_condo_RS, scatter = False, ax=axes[1][1])\n",
    "\n",
    "sns.boxplot(x=x_Econdo_RS[\"Floor No (Final)\"], y=y_Econdo_RS,ax=axes[1][2])\n",
    "sns.regplot(x=x_Econdo_RS[\"Floor No (Final)\"], y=y_Econdo_RS, scatter = False, ax=axes[1][2])\n",
    "\n",
    "\n",
    "\n",
    "axes[0][0].set(xlabel='Floor No (Final)', ylabel='Unit Price ($psf)',title=\"Box Plot Of Unit Price ($psf) Against Floor No (Final) for Apartment New Sales\")\n",
    "axes[0][1].set(xlabel='Floor No (Final)', ylabel='Unit Price ($psf)',title=\"Box Plot Of Unit Price ($psf) Against Floor No (Final) for Condo New Sales\")\n",
    "axes[0][2].set(xlabel='Floor No (Final)', ylabel='Unit Price ($psf)',title=\"Box Plot Of Unit Price ($psf) Against Floor No (Final) for Executive Condo New Sales\")\n",
    "axes[1][0].set(xlabel='Floor No (Final)', ylabel='Unit Price ($psf)',title=\"Box Plot Of Unit Price ($psf) Against Floor No (Final) for Apartment Resales\")\n",
    "axes[1][1].set(xlabel='Floor No (Final)', ylabel='Unit Price ($psf)',title=\"Box Plot Of Unit Price ($psf) Against Floor No (Final) for Condo Resales\")\n",
    "axes[1][2].set(xlabel='Floor No (Final)', ylabel='Unit Price ($psf)',title=\"Box Plot Of Unit Price ($psf) Against Floor No (Final) for Executive Condo Resales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.3 Distance to Public Transportation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the features representing distance to public transportation did not appear in the top three most important features across all six domains, it is important to note that these features do appear to be common across all six domains among the top ten most important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot below, we can see that Unit Price ($psf) is inversely related to two features representing distance to public transport â€“ Bus Distance (log) and MRT Distance (log). As the distance to bus stop and to MRT station decreases, the Unit Price ($psf) increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence\n",
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "\n",
    "\n",
    "def main():\n",
    "    #cal_housing = fetch_california_housing()\n",
    "\n",
    "    # split 80/20 train-test\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(cal_housing.data,\n",
    "    #                                                    cal_housing.target,\n",
    "    #                                                    test_size=0.2,\n",
    "    #                                                    random_state=1)\n",
    "    x_train = x_apart_NS_train\n",
    "    y_train =y_apart_NS_train\n",
    "    x_test = x_apart_NS_test\n",
    "    y_test = y_apart_NS_test\n",
    "    names = x_apart_NS_train.columns[17 & 27]\n",
    "\n",
    "    print(\"Training GBRT...\")\n",
    "    clf = GradientBoostingRegressor(n_estimators=100, max_depth=4,\n",
    "                                    learning_rate=0.1, loss='huber',\n",
    "                                    random_state=1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\" done.\")\n",
    "\n",
    "    print('Convenience plot with ``partial_dependence_plots``')\n",
    "\n",
    "\n",
    "    print('Custom 3d plot via ``partial_dependence``')\n",
    "    fig = plt.figure()\n",
    "\n",
    "    target_feature = (0, 1)\n",
    "    pdp, axes = partial_dependence(clf, target_feature,\n",
    "                                   X=x_train, grid_resolution=50)\n",
    "    XX, YY = np.meshgrid(axes[0], axes[1])\n",
    "    Z = pdp[0].reshape(list(map(np.size, axes))).T\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_surface(XX, YY, Z, rstride=1, cstride=1,\n",
    "                           cmap=plt.cm.BuPu, edgecolor='k')\n",
    "    ax.set_xlabel(names[target_feature[0]])\n",
    "    ax.set_ylabel(names[target_feature[1]])\n",
    "    ax.set_zlabel('Partial dependence')\n",
    "    #  pretty init view\n",
    "    ax.view_init(elev=22, azim=122)\n",
    "    plt.colorbar(surf)\n",
    "    plt.suptitle('Partial dependence of house value on median\\n'\n",
    "                 'age and average occupancy')\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Needed on Windows because plot_partial_dependence uses multiprocessing\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Important Features across Type of Sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, having visualized all important common features across all six domains, we want to identify features that are common across each type of sale to obtain further insights on whether there are features that are only unique to each particular sales type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.1 Resales - Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results obtained above, we can see that Age appears to be a significantly important feature that consistently appear across all property types as the second most important feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x=x_apart_RS[\"Age\"], y=y_apart_RS)\n",
    "sns.regplot(x=x_apart_RS[\"Age\"], y=y_apart_RS, scatter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x=x_condo_RS[\"Age\"], y=y_condo_RS)\n",
    "sns.regplot(x=x_condo_RS[\"Age\"], y=y_condo_RS, scatter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x=x_Econdo_RS[\"Age\"], y=y_Econdo_RS)\n",
    "sns.regplot(x=x_Econdo_RS[\"Age\"], y=y_Econdo_RS, scatter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plots above, we can see that as Age is inversely related to Unit Price ($psf). As Age increases, the Unit Price ($psf) decreases. However, it is also interesting to note that for Apartment and Condominiums, we can see a spike in Unit Price ($psf) at around age 24 for Apartments and age 23 to 26 for Condominiums. Based on business domain knowledge, the sudden rise in price could be due to demand driven by property investors who are interested in profiting from a potential en bloc sale, which typically occurs for properties that were more than 20 years old at the point of sale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
